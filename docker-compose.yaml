version: '3.8'

services:
  location-build:
    image: location-build:develop
    build:
      context: "."
      dockerfile: ".docker/location/build.Dockerfile"

  location:
    build:
      context: "."
      dockerfile: ".docker/location/app.Dockerfile"
#    restart: unless-stopped
    depends_on:
      location-build:
        condition: service_completed_successfully
      postgresql:
        condition: service_healthy
    volumes:
      - './.env:/location/.env'
      - './migrations/location/:/location/migrations/location/'
    ports:
      - ${LOCATION_PORT}:${LOCATION_PORT}

  driver-build:
    image: driver-build:develop
    build:
      context: "."
      dockerfile: ".docker/driver/build.Dockerfile"

  driver:
    build:
      context: "."
      dockerfile: ".docker/driver/app.Dockerfile"
#    restart: unless-stopped
    depends_on:
      location-build:
        condition: service_completed_successfully
      mongodb:
        condition: service_healthy
    volumes:
      - './.env:/driver/.env'
      - './migrations/driver/:/driver/migrations/driver/'
    ports:
      - ${DRIVER_PORT}:${DRIVER_PORT}

  mongodb:
    env_file:
      - .env
    image: mongo:latest
    container_name: mongodb
    restart: unless-stopped
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${DRIVER_DB_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${DRIVER_DB_PASSWORD}
      MONGO_INITDB_DATABASE: ${DRIVER_DB}
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/${DRIVER_DB} --quiet
      interval: 10s
      timeout: 10s
      retries: 3
      start_period: 20s

  postgresql:
    env_file:
      - .env
    image: postgres:latest
    container_name: postgresql
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${LOCATION_DB_USER}
      POSTGRES_PASSWORD: ${LOCATION_DB_PASSWORD}
      POSTGRES_DB: ${LOCATION_DB}
    healthcheck:
      test: "pg_isready -d $$POSTGRES_DB -U $$POSTGRES_USER"
      interval: 10s
      timeout: 5s
      retries: 5

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    ports:
      - "9090:9090"
    restart: unless-stopped
    volumes:
      - ./deployments/prometheus:/etc/prometheus
      - prom_data:/prometheus

  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=grafana
    volumes:
      - ./deployments/grafana:/etc/grafana/provisioning/datasources

  jaeger-all-in-one:
    image: jaegertracing/all-in-one:latest
    restart: always
    ports:
      - "16686:16686"
      - "14268"
      - "14250"

  otel-collector:
    image: otel/opentelemetry-collector:0.88.0
    restart: always
    command: [ "--config=/etc/otel-collector-config.yaml" ]
    volumes:
      - ./deployments/otel/otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "1888:1888"   # pprof extension
      - "8888:8888"   # Prometheus' metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter metrics
      - "13133:13133" # health_check extension
      - "4317:4317"   # OTLP gRPC receiver

    depends_on:
      - jaeger-all-in-one

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "22181:2181"

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "driver:1:1"

volumes:
  prom_data: